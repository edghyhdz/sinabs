{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Sinabs\n",
    "If you're familiar with how SNNs work, you might find this quick overview about *Sinabs* useful.\n",
    "\n",
    "## Sinabs is based on PyTorch\n",
    "All of Sinabs' layers inherit from `torch.nn.Module`. Thus you will be able to access your parameters, wrap layers in a `nn.Sequential` module and all the other things that you would do with a normal PyTorch layer. \n",
    "\n",
    "## How to define your network\n",
    "We want to re-use as much PyTorch functionality as possible. We use Linear, Conv2d and AvgPool layers to define weight matrices, whereas *Sinabs* layers add state as well as the non-linear activation to each of those weight layers. This is a definition of a simple SNN which takes as an input a tensor of (Batch, Time, Channels):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sinabs.layers as sl\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 32),\n",
    "    sl.LIF(tau_mem=20.),\n",
    "    nn.Linear(32, 4),\n",
    "    sl.LIF(tau_mem=40.),\n",
    ")\n",
    "\n",
    "# (Batch, Time, Channels)\n",
    "input = torch.rand(8, 100, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with convolutional connectivity, a `nn.Conv2d` layer only takes as input a tensor of (Batch, Channels, Height, Width). If we feed a tensor that has an additional time dimension (Batch, Time, Channels, Height, Width) to such a layer, we will receive an error. In order for us to apply 2D convolutions across time, we have to make use of a small trick where we flatten batch and time dimension before feeding it to the Conv layer. If the input is flattened, we will need to unflatten it for each Sinabs layer by using `Squeeze` versions of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "conv_model = nn.Sequential(\n",
    "    nn.Conv2d(2, 16, kernel_size=3),\n",
    "    sl.LIFSqueeze(tau_mem=20., batch_size=batch_size),\n",
    "    nn.Conv2d(16, 32, kernel_size=3),\n",
    "    sl.LIFSqueeze(tau_mem=20., batch_size=batch_size),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32, 4),\n",
    ")\n",
    "\n",
    "# (Batch*Time, Channels, Height, Width)\n",
    "input = torch.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5931241afb711235dda64ee4fe99a453ecee36036d1d9ee62f788faeb386adff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
