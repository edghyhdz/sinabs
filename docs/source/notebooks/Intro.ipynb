{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a spiking network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext blackcellmagic\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sinabs.layers as sl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MySNN, self).__init__()\n",
    "        # Spiking Input Layer\n",
    "        self.input1 = sl.InputLayer(input_shape=(1, 64, 64), layer_name=\"input_1\")\n",
    "\n",
    "        # Spiking Conv layer\n",
    "        self.conv1 = sl.SpikingConv2dLayer(\n",
    "            channels_in=1,\n",
    "            image_shape=(64, 64),\n",
    "            channels_out=6,\n",
    "            kernel_shape=(5, 5),\n",
    "            layer_name=\"conv_1\",\n",
    "        )\n",
    "\n",
    "        # Spiking SumPooling layer\n",
    "        self.pool1 = sl.SumPooling2dLayer(\n",
    "            image_shape=(60, 60), pool_size=(3, 3), layer_name=\"pool_1\"\n",
    "        )\n",
    "\n",
    "        # Spiking Conv layer\n",
    "        self.conv2 = sl.SpikingConv2dLayer(\n",
    "            channels_in=6,\n",
    "            image_shape=(20, 20),\n",
    "            channels_out=6,\n",
    "            kernel_shape=(5, 5),\n",
    "            layer_name=\"conv_2\",\n",
    "        )\n",
    "\n",
    "        # Spiking SumPooling layer\n",
    "        self.pool2 = sl.SumPooling2dLayer(\n",
    "            image_shape=(16, 16), pool_size=(4, 4), layer_name=\"pool_2\"\n",
    "        )\n",
    "\n",
    "        # Generating an Equivalent Spiking Dense Layer\n",
    "        self.flatten1 = sl.FlattenLayer(input_shape=(6, 4, 4), layer_name=\"flatten_1\")\n",
    "        self.conv3 = sl.SpikingConv2dLayer(\n",
    "            channels_in=96,\n",
    "            image_shape=(1, 1),\n",
    "            channels_out=10,\n",
    "            kernel_shape=(1, 1),\n",
    "            layer_name=\"conv_3\",\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define your graph\n",
    "        x = self.input1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten1(x)\n",
    "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.conv3(x)\n",
    "        out = x.squeeze()\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySNN(\n",
      "  (input1): InputLayer()\n",
      "  (conv1): SpikingConv2dLayer(\n",
      "    (conv): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (pool1): SumPooling2dLayer(\n",
      "    (pool): LPPool2d(norm_type=1, kernel_size=(3, 3), stride=(3, 3), ceil_mode=False)\n",
      "  )\n",
      "  (conv2): SpikingConv2dLayer(\n",
      "    (conv): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (pool2): SumPooling2dLayer(\n",
      "    (pool): LPPool2d(norm_type=1, kernel_size=(4, 4), stride=(4, 4), ceil_mode=False)\n",
      "  )\n",
      "  (flatten1): FlattenLayer()\n",
      "  (conv3): SpikingConv2dLayer(\n",
      "    (conv): Conv2d(96, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "snn = MySNN()\n",
    "print(snn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Ouput Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn(100, 1, 64, 64)\n",
    "output_data = snn(input_data)\n",
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate rate-based spike trains from normalised float number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between original image and converted spike trains:  8.112542152404785\n",
      "L2 distance between original image and converted spike trains:  2.5845723152160645\n",
      "L2 distance between original image and converted spike trains:  0.825164794921875\n"
     ]
    }
   ],
   "source": [
    "def get_spike_train(time_win):\n",
    "    # randomize an image: 1 channel, 64*64 resolution\n",
    "    input_image = torch.rand(1, 64, 64)\n",
    "    # randomize a tensor accordingly with #time_win per pixel\n",
    "    random_tensor = torch.rand(time_win, 1, 64, 64)\n",
    "    # generating 1 if random number is lower than the pixel value of the input_image\n",
    "    converted_spike_train =  (random_tensor < input_image).float()\n",
    "    # imag_original, is of 64*64 from input_image\n",
    "    img_original = input_image[0]\n",
    "    # img_converted, is the counted spikes over the time_win divided by the time_win\n",
    "    img_converted = converted_spike_train.sum(0)[0]/time_win\n",
    "    # the L2 distance between these two images\n",
    "    dist = torch.dist(img_original, img_converted, 2).item()\n",
    "    print(\"L2 distance between original image and converted spike trains: \", dist)\n",
    "    return converted_spike_train\n",
    "\n",
    "# Longer time_win results in more precise conversion\n",
    "time_win_list = [10, 100, 1000]\n",
    "for time_win in time_win_list:\n",
    "    get_spike_train(time_win)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read out a spike train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between original image and converted spike trains:  2.5908772945404053\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "input_data = get_spike_train(100)\n",
    "output_data = snn(input_data)\n",
    "output_spike_count = output_data.sum(0)\n",
    "print(output_spike_count.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
