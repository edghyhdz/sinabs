{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a spiking network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing all relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sinabs.layers as sl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample definition of a pytorch module using sinabs spiking layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MySNN, self).__init__()\n",
    "        # Spiking Input Layer\n",
    "        self.input1 = sl.InputLayer(input_shape=(1, 64, 64), layer_name=\"input_1\")\n",
    "\n",
    "        # Spiking Conv layer\n",
    "        self.conv1 = sl.SpikingConv2dLayer(\n",
    "            channels_in=1,\n",
    "            image_shape=(64, 64),\n",
    "            channels_out=6,\n",
    "            kernel_shape=(5, 5),\n",
    "            layer_name=\"conv_1\",\n",
    "        )\n",
    "\n",
    "        # Spiking SumPooling layer\n",
    "        self.pool1 = sl.SumPooling2dLayer(\n",
    "            image_shape=(60, 60), pool_size=(3, 3), layer_name=\"pool_1\"\n",
    "        )\n",
    "\n",
    "        # Spiking Conv layer\n",
    "        self.conv2 = sl.SpikingConv2dLayer(\n",
    "            channels_in=6,\n",
    "            image_shape=(20, 20),\n",
    "            channels_out=6,\n",
    "            kernel_shape=(5, 5),\n",
    "            layer_name=\"conv_2\",\n",
    "        )\n",
    "\n",
    "        # Spiking SumPooling layer\n",
    "        self.pool2 = sl.SumPooling2dLayer(\n",
    "            image_shape=(16, 16), pool_size=(4, 4), layer_name=\"pool_2\"\n",
    "        )\n",
    "\n",
    "        # Generating an Equivalent Spiking Dense Layer\n",
    "        self.flatten1 = sl.FlattenLayer(input_shape=(6, 4, 4), layer_name=\"flatten_1\")\n",
    "        self.conv3 = sl.SpikingConv2dLayer(\n",
    "            channels_in=96,\n",
    "            image_shape=(1, 1),\n",
    "            channels_out=10,\n",
    "            kernel_shape=(1, 1),\n",
    "            layer_name=\"conv_3\",\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define your graph\n",
    "        x = self.input1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten1(x)\n",
    "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.conv3(x)\n",
    "        out = x.squeeze()\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now instantiate and visualize the model built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySNN(\n",
      "  (input1): InputLayer()\n",
      "  (conv1): SpikingConv2dLayer(\n",
      "    (thresh_lower): Threshold(threshold=-1.0, value=-1.0)\n",
      "    (conv): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (pool1): SumPooling2dLayer(\n",
      "    (pool): LPPool2d(norm_type=1, kernel_size=(3, 3), stride=(3, 3), ceil_mode=False)\n",
      "  )\n",
      "  (conv2): SpikingConv2dLayer(\n",
      "    (thresh_lower): Threshold(threshold=-1.0, value=-1.0)\n",
      "    (conv): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (pool2): SumPooling2dLayer(\n",
      "    (pool): LPPool2d(norm_type=1, kernel_size=(4, 4), stride=(4, 4), ceil_mode=False)\n",
      "  )\n",
      "  (flatten1): FlattenLayer()\n",
      "  (conv3): SpikingConv2dLayer(\n",
      "    (thresh_lower): Threshold(threshold=-1.0, value=-1.0)\n",
      "    (conv): Conv2d(96, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "snn = MySNN()\n",
    "print(snn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Ouput Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a random input tensor to be processed by the `snn` model.\n",
    "\n",
    "`Note`: The input generated below is not `spikes` and does not make much sense in the context of spiking neural networks but `sinabs` does not check the type of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn(100, 1, 64, 64)\n",
    "output_data = snn(input_data)\n",
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output has the correct dimensions and lasts a 100 time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate rate-based spike trains from normalised float number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the inputs for Spiking Neural Networks are binary values where a 1 at a given time step corresponds to a spike at the corresponding time step.\n",
    "\n",
    "Below is a simple method that converts an image to a stream of spikes. You will see that the longer the time window we use to convert a static image to spikes, the more accurate the data representation is, as evident from the L2 distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between original image and converted spike trains:  8.19106388092041\n",
      "L2 distance between original image and converted spike trains:  2.609668493270874\n",
      "L2 distance between original image and converted spike trains:  0.8394787907600403\n"
     ]
    }
   ],
   "source": [
    "def get_spike_train(time_win, input_image):\n",
    "    input_image = torch.rand(1, 64, 64)\n",
    "    # randomize a tensor accordingly with #time_win per pixel\n",
    "    random_tensor = torch.rand(time_win, 1, 64, 64)\n",
    "    # generating 1 if random number is lower than the pixel value of the input_image\n",
    "    converted_spike_train =  (random_tensor < input_image).float()\n",
    "    # imag_original, is of 64*64 from input_image\n",
    "    img_original = input_image[0]\n",
    "    # img_converted, is the counted spikes over the time_win divided by the time_win\n",
    "    img_converted = converted_spike_train.sum(0)[0]/time_win\n",
    "    # the L2 distance between these two images\n",
    "    dist = torch.dist(img_original, img_converted, 2).item()\n",
    "    print(\"L2 distance between original image and converted spike trains: \", dist)\n",
    "    return converted_spike_train\n",
    "\n",
    "\n",
    "# Define a random image\n",
    "input_image = torch.rand(1, 64, 64)\n",
    "\n",
    "# Longer time_win results in more precise conversion\n",
    "time_win_list = [10, 100, 1000]\n",
    "for time_win in time_win_list:\n",
    "    get_spike_train(time_win, input_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process a spike train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the above method to generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between original image and converted spike trains:  2.638181686401367\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate input spikes\n",
    "input_image = torch.rand(1, 64, 64)\n",
    "input_data = get_spike_train(100, input_image)\n",
    "\n",
    "# Process spikes through the m\n",
    "output_data = snn(input_data)\n",
    "output_spike_count = output_data.sum(0)\n",
    "print(output_spike_count.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
