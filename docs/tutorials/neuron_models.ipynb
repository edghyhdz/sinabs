{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the right neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinabs\n",
    "import sinabs.layers as sl\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a helpful plotting function and some constant current input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evolution(neuron_model: sinabs.layers, input: torch.Tensor):\n",
    "    time_steps = input.shape[1]\n",
    "\n",
    "    neuron_model.reset_states()\n",
    "    v_mem = []\n",
    "    spikes = []\n",
    "    i_syn = []\n",
    "    spike_thresholds = []\n",
    "    for step in range(time_steps):\n",
    "        output = neuron_model(input[:, step])\n",
    "        v_mem.append(neuron_model.v_mem.detach().numpy())\n",
    "        if neuron_model.spike_threshold:\n",
    "            spike_thresholds.append(\n",
    "                torch.as_tensor(neuron_model.spike_threshold).detach().numpy()\n",
    "            )\n",
    "        if hasattr(neuron_model, \"i_syn\") and neuron_model.i_syn:\n",
    "            i_syn.append(neuron_model.i_syn.detach().numpy())\n",
    "        spikes.append(output.sum().detach().numpy())\n",
    "\n",
    "    plt.plot(v_mem, drawstyle=\"steps-post\", label=\"v_mem\")\n",
    "    if neuron_model.activation_fn:\n",
    "        plt.plot(\n",
    "            spike_thresholds,\n",
    "            \"--\",\n",
    "            label=\"spike threshold\",\n",
    "        )\n",
    "        for step, spike in enumerate(spikes):\n",
    "            if spike > 0:\n",
    "                spike_time = step\n",
    "                plt.axvline(x=spike_time, ymax=float(spike), color=\"black\", linewidth=3)\n",
    "        plt.axvline(\n",
    "            x=spike_time, ymax=float(spike), label=\"spikes\", color=\"black\", linewidth=3\n",
    "        )\n",
    "    if len(i_syn) > 0:\n",
    "        plt.plot(i_syn, drawstyle=\"steps-post\", linewidth=3, label=\"i_syn\", color=\"C6\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.title(f\"{neuron_model.__class__.__name__} neuron dynamics\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "const_current = torch.ones((1, 100, 1)) * 0.03\n",
    "single_current = torch.zeros((1, 100, 1))\n",
    "single_current[:, 0] = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate and Fire neuron\n",
    "This neuron has no leakage and simply integrates all the input it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iaf_neuron = sl.IAF()\n",
    "plot_evolution(iaf_neuron, const_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can activate synaptic currents in this neuron model, which will integrate all inputs into its i_syn state, which will then be added to the membrane potential at every step. If we use a single current injection at the first step while also using the static synaptic currents, we essentially achieve the same result as with constant input current in the previous plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iaf_neuron = sl.IAF(use_synaptic_state=True)\n",
    "plot_evolution(iaf_neuron, single_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky Integrate and Fire neuron\n",
    "This neuron integrates the input and decays its state at every time step. It emits a spike whenever the membrane potential is above the spike threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif_neuron = sl.LIF(tau_mem=40.0, norm_input=False)\n",
    "plot_evolution(lif_neuron, const_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, no synaptic dynamics are used. We can enable that by setting tau_syn. Note that instead of a constant current, we now inject current only at the first time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif_neuron = sl.LIF(tau_mem=40.0, tau_syn=30.0, norm_input=False)\n",
    "plot_evolution(lif_neuron, single_current * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky integrator neuron\n",
    "Same as LIF, just without activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_leak_neuron = sl.ExpLeak(tau_mem=60.0)\n",
    "plot_evolution(exp_leak_neuron, const_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Leaky Integrate and Fire neuron\n",
    "This is a LIF neuron with an adaptive threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alif_neuron = sl.ALIF(tau_mem=40.0, tau_adapt=40.0, adapt_scale=20, norm_input=False)\n",
    "plot_evolution(alif_neuron, const_current * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5931241afb711235dda64ee4fe99a453ecee36036d1d9ee62f788faeb386adff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
